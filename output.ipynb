{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Recursion\n",
    "\n",
    "#### Algorithm used (technique)\n",
    "\n",
    "``Recursion Backtracking``\n",
    "\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "Recursion backtracking is an algorithmic technique used to find all solutions to a problem by exploring all potential solutions incrementally. It involves calling the same function repeatedly with new parameters, diving deeper into the problem. Once a solution path fails (for example, when a queen cannot be placed in any column for a row in the n-Queens problem), the algorithm \"backtracks\" to the previous step and tries other possible options.\n",
    "\n",
    "\n",
    "- **Recursion** allows the algorithm to move step-by-step through a problem, progressing deeper into potential solutions.\n",
    "\n",
    "- **Backtracking** ensures that if a solution is not valid at any point, the algorithm will retract its steps and explore different possibilities from the previous level of recursion.\n",
    "\n",
    "- **Base Case** - When all conditions for a solution are met (e.g., all queens are placed on the board without conflicts), the algorithm adds the solution to the list.\n",
    "\n",
    "- **Termination Case** - If no valid solution is found after trying all possibilities, the algorithm ends that recursive path.\n",
    "\n",
    "\n",
    "##### Real World Problem\n",
    "\n",
    "``N-Queens Problem``\n",
    "\n",
    "A classic backtracking example where the goal is to place ``n`` queens on a ``n x n`` chessboard such that no two queens threaten each other.\n",
    "For each queen, the algorithm tries placing it in every column of a row, checking if the move is safe (i.e., the queen doesn't share the same column, diagonal, or anti-diagonal with other queens). If a queen can't be safely placed, the algorithm backtracks, moving the previous queens to different positions.\n",
    "\n",
    "\n",
    "#### Solution\n",
    "\n",
    "The backtracking recursion will go through the process of trying different configurations for the queens and will use backtracking when a conflict arises (when a queen can't be placed safely). Which continues until either a valid configuration is found or all possibilities are exhausted.\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "| **Recursion**            |                          | **Iterative**              |                          |\n",
    "| ------------------------ | ------------------------ | -------------------------- | ------------------------ |\n",
    "| **Advantages**            | - Simple and easy to implement.                             | **Advantages**             | - Avoids recursion stack overflow.                          |\n",
    "|                          | - Directly models the problem, making it intuitive.        |                           | - Can be more efficient for large problem sizes.             |\n",
    "|                          | - Good for small to medium-sized problems.                  |                           | - More control over the stack.                                |\n",
    "| **Limitations**           | - Can result in stack overflow for large problem sizes.    | **Limitations**            | - More complex to implement and reason about.                |\n",
    "|                          | - Can be less memory efficient due to recursion overhead.  |                           | - Requires manual management of state (stack).               |\n",
    "|                          | - Less efficient for very large inputs.                     |                           | - Less intuitive compared to recursion.                       |\n",
    "| **Use Case**              | - Best for smaller problems or where recursion depth is manageable. | **Use Case**              | - Best for larger problems where stack overflow is a concern. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Check if there's a queen in the same column\n",
    "def is_safe(board, row, col, n):\n",
    "    # Loop thru each row\n",
    "    for i in range(row):\n",
    "        # If a queen is in the same column\n",
    "        # board[i] represents as the column in the row being looped\n",
    "        if (board[i] == col or \n",
    "            # If both are -1, then there is a queen (diagonally)\n",
    "            board[i] - i == col - row or # Checks left-to-right\n",
    "            # If both are the same value, then there is a queen\n",
    "            board[i] + i == col + row): # Checks right-to-left\n",
    "            return False\n",
    "    # If it doesn't pass the conditions, then we can place the queen\n",
    "    return True\n",
    "\n",
    "def solve_n_queens(board, row, n, solutions):\n",
    "    # If the row is now equal to the n (the size of board), we add the solution\n",
    "    if row == n:\n",
    "        # Save the current state of board so it won't be modified in backtracking\n",
    "        solutions.append(board[:])\n",
    "        return\n",
    "    \n",
    "    # Try placing queens in all columns for the current row\n",
    "    for col in range(n):\n",
    "        # For each column, we'll check if it's safe to place the queen\n",
    "        if is_safe(board, row, col, n):\n",
    "            board[row] = col  # Place the queen\n",
    "            solve_n_queens(board, row + 1, n, solutions)  # Recur for the next row\n",
    "            board[row] = -1  # Backtrack, remove the queen\n",
    "\n",
    "def print_solution(board):\n",
    "    # Loop thru each row, checking if we place the queen or not\n",
    "    # Row in here represents the position of each queen in each row\n",
    "    # Not technically the row in what'd you think in a 2d array\n",
    "    # So it's a single-dimension array \n",
    "    for row in board:\n",
    "        # Check each column in the board (the queens' positions)\n",
    "        # If there is a queen print Q if not then print a dot\n",
    "        # We use len(board) instead of explicitly passing n for adaptability\n",
    "        # If there ever is a case that n wasn't passed around correctly\n",
    "        # Or if the recursion modified the board\n",
    "        line = ['Q' if col == row else '.' for col in range(len(board))]\n",
    "        print(\" \".join(line))\n",
    "    print(\"-\" * len(board) * 2)\n",
    "\n",
    "# Initializer method\n",
    "def n_queens(n):    \n",
    "    solutions = [] # Initialize array of solutions\n",
    "    board = [-1] * n  # Initialize the board with -1 (no queens placed)\n",
    "    \n",
    "    solve_n_queens(board, 0, n, solutions) # Base\n",
    "    \n",
    "    # After the many many recursions, we then (only) print all the valid solutions\n",
    "    print(f\"Found {len(solutions)} solutions for {n}-Queens:\")\n",
    "    for solution in solutions:\n",
    "        print_solution(solution)\n",
    "\n",
    "# The size of the board\n",
    "n = 6\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "n_queens(n)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Completed in {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def is_safe(board, row, col, n):\n",
    "    for i in range(row):\n",
    "        if board[i] == col or \\\n",
    "            board[i] - i == col - row or \\\n",
    "            board[i] + i == col + row:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def solve_n_queens(n):\n",
    "    # Stack to store (row, board_state) tuples\n",
    "    stack = []\n",
    "    solutions = []\n",
    "\n",
    "    # Initialize the board with -1 (no queens placed)\n",
    "    board = [-1] * n\n",
    "    row = 0  # Start at the first row\n",
    "\n",
    "    while row >= 0:\n",
    "        # Try placing a queen in the current row\n",
    "        safe = False\n",
    "        for col in range(board[row] + 1, n):\n",
    "            if is_safe(board, row, col, n):\n",
    "                board[row] = col  # Place queen in column\n",
    "                stack.append((row, board[:]))  # Save the current state\n",
    "                safe = True\n",
    "                break  # Move to the next row\n",
    "        \n",
    "        if not safe:\n",
    "            if row == 0:  # No solution found, we're done\n",
    "                break\n",
    "            board[row] = -1  # Backtrack, remove the queen\n",
    "            row -= 1  # Go back to the previous row\n",
    "        else:\n",
    "            row += 1  # Move to the next row\n",
    "    \n",
    "        # Check if we've reached the last row\n",
    "        if row == n:\n",
    "            solutions.append(board[:])  # Found a solution\n",
    "            row -= 1  # Backtrack\n",
    "\n",
    "    # Output all solutions\n",
    "    print(f\"Found {len(solutions)} solutions for {n}-Queens:\")\n",
    "    for solution in solutions:\n",
    "        for row in solution:\n",
    "            line = ['Q' if col == row else '.' for col in range(n)]\n",
    "            print(\" \".join(line))\n",
    "        print()\n",
    "\n",
    "    return solutions\n",
    "\n",
    "n = 6\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "solve_n_queens(n)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Iterative backtracking completed in {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "#### Algorithms used \n",
    "\n",
    "`Quick sort` & `Selection sort`\n",
    "\n",
    "#### Explanation\n",
    "\n",
    " ``Selection Sort`` works by repeatedly selecting the minimum element from an unsorted portion of the list and swapping it with the element at the beginning of that portion. It continues this process until the entire list is sorted.\n",
    "\n",
    " ``Quick Sort`` is a divide-and-conquer technique. It works by selecting a pivot element from the list and partitioning the other elements into two sublists—those less than the pivot and those greater than the pivot. The algorithm then recursively sorts the sublists.\n",
    "\n",
    "\n",
    "#### Real World Problems\n",
    "\n",
    "This type of sorting might be used in applications like:\n",
    "\n",
    "- ``File Management Systems`` for large collections of files by name, creation date, or file size.\n",
    "\n",
    "- ``Financial Data`` for random financial numbers for analysis, such as transaction amounts.\n",
    "\n",
    "- ``Event Scheduling`` for dates for planning events, appointments, or deadlines.\n",
    "\n",
    "\n",
    "#### Time Complexity Comparison \n",
    "*May vary since this data was taken from a previous run*\n",
    "\n",
    "| **Selection Sort**                | **Time Elapsed (Small Data)** | **Time Elapsed (Large Data)** | **Quick Sort**                | **Time Elapsed (Small Data)** | **Time Elapsed (Large Data)** |\n",
    "| --------------------------------- | ----------------------------- | ----------------------------- | ----------------------------- | ----------------------------- | ----------------------------- |\n",
    "| **Files**                         | 0.000013 seconds              | 0.020218 seconds              | **Files**                     | 0.000016 seconds              | 0.001171 seconds              |\n",
    "| **Numbers**                       | 0.000009 seconds              | 0.016659 seconds              | **Numbers**                   | 0.000011 seconds              | 0.001046 seconds              |\n",
    "| **Dates**                         | 0.000006 seconds              | 0.020236 seconds              | **Dates**                     | 0.000008 seconds              | 0.001185 seconds              |\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Key Takeaways\n",
    "\n",
    "- ``Quick Sort`` outperforms ``Selection Sort`` as the data size grows, both for small and large datasets.\n",
    "\n",
    "- For small data, both algorithms show negligible time differences, but ``Quick Sort`` is faster.\n",
    "\n",
    "- As the data size increases, ``Quick Sort`` remains significantly faster, especially when dealing with large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Generate mock filenames without worrying about their file sizes\n",
    "# This speeds up lookups as we don't need to fetch or wait for the actual file data\n",
    "def generate_filenames(n):\n",
    "    return [f\"file_{i}.txt\" for i in range(1, n+1)]\n",
    "\n",
    "# Generate a list of random numbers\n",
    "# The number of random numbers is determined by the n parameter\n",
    "# While the start and end parameters define the range (default: 1 to 1000)\n",
    "# The n value varies based on the provided configuration\n",
    "def generate_random_numbers(n, start=1, end=1000):\n",
    "    return [random.randint(start, end) for _ in range(n)]\n",
    "\n",
    "# Generate a list of random dates\n",
    "def generate_random_dates(n):\n",
    "    # Base date (January 1, 2020)\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    \n",
    "    # From the base, we add a random generated day\n",
    "    # For example, if the random is 5 then we add 5 days to the base date\n",
    "    # So in here we randomized from 0 to 1000 days to add\n",
    "    # Don't forget that this is an array, so we loop until we reach the n parameter\n",
    "    return [start_date + timedelta(days=random.randint(0, 1000)) for _ in range(n)]\n",
    "\n",
    "def selection_sort(arr):\n",
    "    n = len(arr) # Get the size of array\n",
    "    \n",
    "    for i in range(n): \n",
    "        # At the start we initialize the minimum index which at first would be the first index\n",
    "        # Then as it loops, it will be modified to the least of the least index in the array\n",
    "        min_idx = i\n",
    "        \n",
    "        # j in here represents the next index of i\n",
    "        # The loop's start is incremented by 1\n",
    "        # Basically decreasing the elements of the array in each loop\n",
    "        # For example, we were given a n of 5\n",
    "        # That would be like, 1-2-3-4-5\n",
    "        # Doesn't sound like much but it means that in every loop\n",
    "        # we start at the next index so in result the elements decreases\n",
    "        for j in range(i+1, n):\n",
    "            # At the base we check if the j here in this current loop is less than the minimum index\n",
    "            # But as the loop goes on the minimum index also changes (if the condition was met)\n",
    "            if arr[j] < arr[min_idx]:\n",
    "                # If the condition was met then modify the minimum index\n",
    "                # The j in here will now be the new minimum index\n",
    "                min_idx = j\n",
    "        # After the second loop, in this first loop we then swap\n",
    "        # Swapping here takes the initial index then the winner of the second loop (the min index)\n",
    "        # To where the initial index was before\n",
    "        # Thus we call it \"selection\" sort, cuz we select what we need to swap\n",
    "        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n",
    "    return arr\n",
    "\n",
    "def quick_sort(arr):\n",
    "    # If the array has one or zero elements, it's already sorted, so return it as is\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "      \n",
    "    # Our reference to compare the right and left side of the array\n",
    "    # Essentially it is the element that is in the middle of the (current) array\n",
    "    pivot = arr[len(arr) // 2]\n",
    "    \n",
    "    # Left side of the array (or the lesser elements of the current pivot)\n",
    "    # We add the elements that meet the condition (if the element is less than the reference)\n",
    "    left = [x for x in arr if x < pivot]\n",
    "    \n",
    "    # We just get the middle element from here\n",
    "    middle = [x for x in arr if x == pivot]\n",
    "    \n",
    "    # Right side of the array (or the greater elements of the current pivot)\n",
    "    # Same logic for the left side of the array but now \n",
    "    # the condition is if the element is greater than reference\n",
    "    right = [x for x in arr if x > pivot]\n",
    "    \n",
    "    # Recursively do method to the left and right sub-arrays,\n",
    "    # and concatenate the results: left + middle + right\n",
    "    return quick_sort(left) + middle + quick_sort(right)\n",
    "\n",
    "small_dataset_size = 10\n",
    "large_dataset_size = 1000\n",
    "\n",
    "small_files = generate_filenames(small_dataset_size)\n",
    "large_files = generate_filenames(large_dataset_size)\n",
    "\n",
    "small_numbers = generate_random_numbers(small_dataset_size)\n",
    "large_numbers = generate_random_numbers(large_dataset_size)\n",
    "\n",
    "small_dates = generate_random_dates(small_dataset_size)\n",
    "large_dates = generate_random_dates(large_dataset_size)\n",
    "\n",
    "\n",
    "# Data to process\n",
    "print(\"Processing mock files..\\n\")\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Small data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_small_files_selection = selection_sort(small_files.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Selection Sort - Small Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_small_files_quick = quick_sort(small_files.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Quick Sort - Small Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Large data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_large_files_selection = selection_sort(large_files.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Selection Sort - Large Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_large_files_quick = quick_sort(large_files.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Quick Sort - Large Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Data to process\n",
    "print(\"Processing random numbers..\\n\")\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Small data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_small_numbers_selection = selection_sort(small_numbers.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Selection Sort - Small Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_small_numbers_quick = quick_sort(small_numbers.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Quick Sort - Small Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Large data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_large_numbers_selection = selection_sort(large_numbers.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Selection Sort - Large Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_large_numbers_quick = quick_sort(large_numbers.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Quick Sort - Large Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Data to process\n",
    "print(\"Processing random dates..\\n\")\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Small data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_small_dates_selection = selection_sort(small_dates.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Selection Sort - Small Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_small_dates_quick = quick_sort(small_dates.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Quick Sort - Small Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Large data:\")\n",
    "\n",
    "# For selection\n",
    "start_time = time.perf_counter()\n",
    "sorted_large_dates_selection = selection_sort(large_dates.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Selection Sort - Large Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.perf_counter()\n",
    "sorted_large_dates_quick = quick_sort(large_dates.copy())\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Quick Sort - Large Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "#### Algorithms Used\n",
    "\n",
    "`Binary Search` & `Interpolation Search`\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "Both Binary Search and Interpolation Search are efficient searching algorithms used to find a specific element in a sorted dataset. The two differ in how they navigate through the data:\n",
    "\n",
    "``Binary Search``\n",
    "\n",
    "- **Divide and conquer** strategy.\n",
    "\n",
    "- Works by repeatedly dividing the search space in half.\n",
    "\n",
    "- The algorithm compares the target with the middle element and narrows down the search space to either the left or right half.\n",
    "\n",
    "\n",
    "``Interpolation Search``\n",
    "\n",
    "- **Estimate the position** of the target based on the value.\n",
    "\n",
    "- It assumes that the values are uniformly distributed, estimating the target’s position based on a linear interpolation between the low and high bounds.\n",
    "\n",
    "- If the estimate points to an element that isn’t the target, the search space is adjusted accordingly.\n",
    "\n",
    "Both algorithms are designed for sorted datasets but have different use cases based on the distribution of the data.\n",
    "\n",
    "##### Real World Problem\n",
    "\n",
    " - **Binary Search** (Stock Price Lookup)\n",
    "    - Imagine you are trying to find the stock price on a specific date from a list of sorted dates and prices. This algorithm is ideal here because the data is already sorted (by date), and you can efficiently find the price for any given date by halving the search space with each comparison.\n",
    "\n",
    " - **Interpolation Search** (Predicting the Value)\n",
    "    - For predicting values (such as sales for a given year), this algorithm is useful when the data is uniformly distributed. The algorithm estimates the target’s position based on the values surrounding it, offering a more efficient search for large datasets where the values are evenly spaced.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "- **Binary Search** narrows down the search to the date of interest. This allows for efficient retrieval of the stock price on that date.\n",
    "\n",
    "- **Interpolation Search** estimates the position of the target year based on the years provided. If the data points (e.g., sales over multiple years) are evenly distributed, this search method will be faster than Binary Search in terms of comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Our sample data, should be sorted though\n",
    "dates = ['2023-01-01', '2023-02-01', '2023-03-01', '2023-04-01', '2023-05-01']\n",
    "prices = [150, 170, 160, 180, 175]\n",
    "\n",
    "def binary_search(dates, target_date):\n",
    "    # Initialize the low (left) as 0\n",
    "    # Initialize the high (right) as the last index\n",
    "    # len(dates) doesn't start at 0 that's why we have to subtract it by 1\n",
    "    low, high = 0, len(dates) - 1\n",
    "    \n",
    "    # Keep this process on until the low isn't less or equal to high\n",
    "    while low <= high:\n",
    "        # Initialize the middle index\n",
    "        # This divides and gets the remainder of the result\n",
    "        mid = (low + high) // 2\n",
    "        \n",
    "        # Check if it is what we're looking for\n",
    "        if dates[mid] == target_date:\n",
    "            return mid  # Return the index where the date is found\n",
    "\n",
    "        # If not, check if it is less than the target\n",
    "        elif dates[mid] < target_date:\n",
    "            # We then add the middle index by 1\n",
    "            # It just searches/moves to the right half of the array\n",
    "            low = mid + 1\n",
    "        # If the middle index is not less than the target\n",
    "        else:\n",
    "            # So now we search/move to the left half of the array\n",
    "            high = mid - 1\n",
    "    return -1  # Return -1 if the date is not found\n",
    "\n",
    "target_date = '2023-03-01'\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "index = binary_search(dates, target_date)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "if index != -1:\n",
    "    print(f\"The stock price on {target_date} was {prices[index]}\")\n",
    "else:\n",
    "    print(f\"Stock price for {target_date} not found\")\n",
    "    \n",
    "print(f\"Completed in {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our sample data, should be sorted though also\n",
    "years = [2000, 2005, 2010, 2012, 2015, 2020]\n",
    "sales = [100, 150, 200, 250, 300, 400]\n",
    "\n",
    "def interpolation_search(years, target_year):\n",
    "    # Same initialization for the Binary Search\n",
    "    low, high = 0, len(years) - 1\n",
    "    \n",
    "    # A pretty complex set of condition here\n",
    "    # We continue if the low is less than or equal to high\n",
    "    # And we also check if the target is greater or equal to the low value of the array\n",
    "    # Then vice versa for the last condition\n",
    "    while low <= high and target_year >= years[low] and target_year <= years[high]:\n",
    "        # We calculate the position from here on using the interpolation formula\n",
    "        # This estimates where the target year might be, based on the values at low and high\n",
    "        pos = low + ((target_year - years[low]) * (high - low)) // (years[high] - years[low])\n",
    "\n",
    "        # Check if the target year is found at the calculated position pos\n",
    "        if years[pos] == target_year:\n",
    "            return pos  # Return the index if the year is found\n",
    "\n",
    "        # If the target year is greater than the value at pos, move the low boundary up (right)\n",
    "        elif years[pos] < target_year:\n",
    "            low = pos + 1\n",
    "        # If the target year is smaller than the value at pos, move the high boundary down (left)\n",
    "        else:\n",
    "            high = pos - 1\n",
    "\n",
    "        # Return -1 if the year is not found in the list\n",
    "        return -1\n",
    "\n",
    "target_year = 2012\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "index = interpolation_search(years, target_year)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "if index != -1:\n",
    "    print(f\"Sales in {target_year} were predicted to be {sales[index]}\")\n",
    "else:\n",
    "    print(f\"Sales data for {target_year} not found\")\n",
    "    \n",
    "print(f\"Completed in {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "``Dynamic Programming (DP)`` is an optimization technique used to solve problems by breaking them down into smaller subproblems and storing the results of these subproblems to avoid redundant calculations. It is particularly useful when a problem can be divided into overlapping subproblems.\n",
    "\n",
    "- **Memoization**: DP uses a bottom-up approach where we store results of subproblems in a table (or array) to avoid recalculating them repeatedly.\n",
    "\n",
    "- **Optimal Substructure**: The solution to a problem depends on solutions to smaller subproblems, which is the key property of DP.\n",
    "\n",
    "- **Overlapping Subproblems**: The problem can be broken down into subproblems which are solved multiple times, and these subproblems can be solved independently.\n",
    "\n",
    "##### Real World Problems\n",
    "\n",
    " ``Fibonacci Problem`` involves calculating the nth Fibonacci number where each number is the sum of the two preceding ones. DP helps to store previous Fibonacci numbers to avoid recalculating them repeatedly.\n",
    "\n",
    " ``Knapsack Problem`` is a classical optimization problem where you have a set of items, each with a weight and a value, and a knapsack with a weight limit. The goal is to maximize the total value of the items without exceeding the capacity of the knapsack.\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "| **Dynamic Programming**           |                              | **Recursion**               |                              |\n",
    "|-----------------------------------|------------------------------|-----------------------------|------------------------------|\n",
    "| **Advantages**                    | - More efficient for large inputs due to memoization. | **Advantages**              | - Simple and easy to implement.                             |\n",
    "|                                   | - Avoids redundant calculations, saving time. |                             | - Directly models the problem, making it intuitive.        |\n",
    "|                                   | - Suitable for problems with overlapping subproblems. |                             | - Good for small to medium-sized problems.                  |\n",
    "| **Limitations**                   | - May use a lot of memory to store intermediate results. | **Limitations**             | - Can result in stack overflow for large problem sizes.    |\n",
    "|                                   | - Requires more time to set up compared to recursive solutions. |                             | - Can be less memory efficient due to recursion overhead.  |\n",
    "|                                   | - Requires more complex logic for table management. |                             | - Less efficient for very large inputs.                     |\n",
    "| **Use Case**                      | - Best for problems with overlapping subproblems or when optimization is required. | **Use Case**               | - Best for smaller problems or when recursion depth is manageable. |\n",
    "| **Execution Time (for n=10)**     | 0.000015 seconds (may vary)             | **Execution Time**          | 0.000925 seconds (may vary)             |\n",
    "\n",
    "#### Key Takeaways\n",
    "\n",
    "- ``Dynamic Programming`` is more efficient for larger inputs due to memoization, which helps avoid redundant calculations. It’s particularly beneficial for problems that have overlapping subproblems, as it saves time by storing intermediate results.\n",
    "\n",
    "  - can be memory-intensive, as it requires storage for intermediate results, and setting up the solution can be more complex. However, it’s the preferred approach when optimization is needed for problems with repeated subproblems.\n",
    "\n",
    "- ``Recursion``, while intuitive and simple to implement, is better suited for smaller problems or when the recursion depth is manageable. It can be less efficient for large inputs and may suffer from stack overflow issues.\n",
    "  \n",
    "  - ideal for problems that naturally fit into a recursive model and when dealing with small to medium-sized inputs. However, for very large inputs, its efficiency and memory usage can become a concern due to the overhead of recursion calls.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def fibonacci_dp(n):\n",
    "    # Base conditions\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "\n",
    "    # Initialize an array of zeroes with the length of the n and add 1\n",
    "    # Why add 1? Because we need to reference the first index\n",
    "    dp = [0] * (n + 1)\n",
    "    \n",
    "    # Set the first and second index as 0,1 (fixed for fibo)\n",
    "    dp[0], dp[1] = 0, 1\n",
    "    \n",
    "    # Start at index 3, since we've come across the indices 1 and 2\n",
    "    # We complement the stop by adding 1 since earlier we added 1 for the initial array\n",
    "    for i in range(2, n + 1):\n",
    "        # For the current index in the loop\n",
    "        # We calculate the previous index value and the previous previous index of the value\n",
    "        # Like one step back then two steps back\n",
    "        # So like you know just add it\n",
    "        dp[i] = dp[i - 1] + dp[i - 2]\n",
    "    \n",
    "    # After the loop, we return the result\n",
    "    return dp[n]\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "print(\"Fibonacci DP Result:\", fibonacci_dp(10))\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Fibonacci DP Execution Time: {end_time - start_time:0.6f} seconds\")\n",
    "\n",
    "def fibonacci_recursive(n):\n",
    "    # Base conditions\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "      \n",
    "    # For any other value of n, calculate the Fibonacci number by calling the function recursively\n",
    "    # This calls this method for (n-1) and (n-2), summing their results\n",
    "    return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)\n",
    "\n",
    "# Measure performance for Fibonacci Recursive\n",
    "start_time = time.perf_counter()\n",
    "print(\"\\nFibonacci Recursive Result:\", fibonacci_recursive(10))\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Fibonacci Recursive Execution Time: {end_time - start_time:0.6f} seconds\")\n",
    "\n",
    "def knapsack_dp(weights, values, capacity):\n",
    "    # Get the number of items (length of weights array)\n",
    "    n = len(weights)\n",
    "    \n",
    "    # Create a 2D array to store the max value for each item and capacity combo\n",
    "    # Rows = items (0 to n), Columns = capacities (0 to capacity)\n",
    "    # Add 1 to both dimensions to account for the \"0-item\" and \"0-capacity\" cases\n",
    "    dp = [[0] * (capacity + 1) for _ in range(n + 1)]\n",
    "    print(dp)\n",
    "    print()\n",
    "    # Start looping through the items (row by row)\n",
    "    # Though we start at row 1, because row 0 is our reference\n",
    "    for i in range(1, n + 1):\n",
    "        # Now loop through all possible capacities (column by column)\n",
    "        # Stop at capacity that is added by 1 to account for the zero base initialization\n",
    "        for w in range(capacity + 1):\n",
    "            # Check if the current item's weight can fit in the current capacity\n",
    "            # At the base, since i is index 1 then this turns into index 0\n",
    "            # It lags behind by 1 each loop \n",
    "            # W here represents the current column of our dp so at the first it would reference row 0 which is all zero columns\n",
    "            \n",
    "            # print(weights[i-1], \"<=\", w)\n",
    "            \n",
    "            if weights[i - 1] <= w:\n",
    "                # If the condition is met, we calculate the max value\n",
    "                # So we've got two options\n",
    "                # Option 1: Don't include the current item (value from the row above)\n",
    "                # Option 2: Include the current item:\n",
    "                #   - Subtract its weight from the current capacity\n",
    "                #   - Add its value to the result of that remaining capacity (row above)\n",
    "                dp[i][w] = max(dp[i - 1][w], dp[i - 1][w - weights[i - 1]] + values[i - 1])\n",
    "                \n",
    "                # print(dp)\n",
    "            else:\n",
    "                # If it doesn't fit, just carry over the value from the row above (previous item)\n",
    "                dp[i][w] = dp[i - 1][w]\n",
    "\n",
    "    # This represents the max value we can get for the given capacity and all items\n",
    "    return dp[n][capacity]\n",
    "\n",
    "\n",
    "weights = [1, 3, 4, 5]\n",
    "values = [10, 40, 50, 70]\n",
    "capacity = 4\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "print(\"\\nKnapsack DP Result:\", knapsack_dp(weights, values, capacity))  \n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Knapsack DP Execution Time: {end_time - start_time:0.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy\n",
    "\n",
    "### Explanation\n",
    "\n",
    "The ``Greedy Algorithm`` for the Knapsack problem works by making the best choice at each step based on a specific criterion, which is typically the **value-to-weight ratio** of the items. The items are first sorted by their value-to-weight ratio in descending order, and then they are added to the knapsack until the capacity is reached. If an item cannot be completely added (due to capacity limitations), it is included fractionally.\n",
    "\n",
    "\n",
    "``Strengths``\n",
    "\n",
    "- **Efficiency**: Greedy algorithms are generally fast, with a time complexity of \\(O(n \\log n)\\) due to the sorting step.\n",
    "\n",
    "- **Simplicity**: The greedy approach is easy to understand and implement, requiring fewer computational steps compared to other methods.\n",
    "\n",
    "- **Low Space Complexity**: Greedy algorithms typically require \\(O(n)\\) space, as they only need to store the items and their corresponding ratios.\n",
    "\n",
    "``Limitations``\n",
    "\n",
    "- **Suboptimal Solution**: Greedy algorithms may not always provide the optimal solution. Since the algorithm makes decisions based on local optimization (best immediate choice), it may fail to find the best global solution.\n",
    "\n",
    "- **Limited Applicability**: This approach works well only for problems with the **greedy-choice property** and **optimal substructure**, which may not be present in all optimization problems.\n",
    "\n",
    "- **No Backtracking**: Once a decision is made, the algorithm doesn't reconsider it. This can result in missing out on better choices that may have emerged later.\n",
    "\n",
    "\n",
    "#### Divide-and-Conquer Approach\n",
    "\n",
    "The ``Divide-and-Conquer`` approach for the Knapsack problem involves breaking the problem down into smaller subproblems. Specifically, the problem is divided by recursively deciding whether to include an item or exclude it, while tracking the best total value for each combination of included/excluded items. The decision process follows these steps:\n",
    "\n",
    "1. If the current item can fit in the knapsack (i.e., its weight is less than or equal to the remaining capacity), both the inclusion and exclusion of the item are considered.\n",
    "\n",
    "2. The process is repeated for smaller subproblems, until all items are either considered or excluded.\n",
    "\n",
    "This method guarantees an optimal solution, but it has an exponential time complexity of \\(O(2^n)\\), making it inefficient for large problem sizes. It is primarily used when the problem is small enough or when a recursive approach is desired.\n",
    "\n",
    "\n",
    "#### Comparison of Solutions\n",
    "\n",
    "| Algorithm               | Time Complexity   | Space Complexity | Optimal Solution? | When to Use                                       |\n",
    "|-------------------------|-------------------|------------------|------------------|--------------------------------------------------|\n",
    "| **Greedy Knapsack**      | \\(O(n \\log n)\\)   | \\(O(n)\\)         | No               | Suitable when an approximate solution is acceptable, or when greedy-choice property holds. |\n",
    "| **Dynamic Programming**  | \\(O(n \\times W)\\) | \\(O(n \\times W)\\) | Yes              | Best when an exact solution is needed, and the problem size is manageable. |\n",
    "| **Divide and Conquer**   | \\(O(2^n)\\)        | \\(O(n)\\)         | Yes              | Useful for small problems or when a recursive approach is preferred. |\n",
    "\n",
    "\n",
    "#### Performance Comparison\n",
    "\n",
    "| Algorithm               | Time Complexity   | Space Complexity | Optimal Solution | When to Use                                       |\n",
    "|-------------------------|-------------------|------------------|------------------|--------------------------------------------------|\n",
    "| **Greedy**              | \\(O(n \\log n)\\)   | \\(O(n)\\)         | No               | When an approximate solution is acceptable. |\n",
    "| **Dynamic Programming** | \\(O(n \\times W)\\) | \\(O(n \\times W)\\) | Yes              | When an exact solution is needed for a given capacity. |\n",
    "| **Divide-and-Conquer**  | \\(O(2^n)\\)        | \\(O(n)\\)         | Yes              | Suitable for small problems or when a recursive approach is desired. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_knapsack(weights, values, capacity):\n",
    "    n = len(weights)\n",
    "    items = sorted([(values[i], weights[i], values[i] / weights[i]) for i in range(n)], \n",
    "    key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    total_value = 0\n",
    "    for value, weight, ratio in items:\n",
    "        if capacity >= weight:\n",
    "            capacity -= weight\n",
    "            total_value += value\n",
    "        else:  \n",
    "            total_value += value * (capacity / weight)\n",
    "            break\n",
    "\n",
    "    return total_value\n",
    "\n",
    "weights = [1, 3, 4, 5]\n",
    "values = [10, 40, 50, 70]\n",
    "capacity = 8\n",
    "print(greedy_knapsack(weights, values, capacity))  \n",
    "\n",
    "def knapsack_divide_and_conquer(weights, values, capacity, n):\n",
    "    if n == 0 or capacity == 0:\n",
    "        return 0\n",
    "\n",
    "    if weights[n - 1] > capacity:\n",
    "        return knapsack_divide_and_conquer(weights, values, capacity, n - 1)\n",
    "\n",
    "    \n",
    "    include = values[n - 1] + knapsack_divide_and_conquer(weights, values, capacity - weights[n - 1], n - 1)\n",
    "    exclude = knapsack_divide_and_conquer(weights, values, capacity, n - 1)\n",
    "\n",
    "    return max(include, exclude)\n",
    "\n",
    "weights = [1, 3, 4, 5]\n",
    "values = [10, 40, 50, 70]\n",
    "capacity = 8\n",
    "n = len(weights)\n",
    "print(knapsack_divide_and_conquer(weights, values, capacity, n))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Algorithms\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "#### ``Dijkstra’s Algorithm``\n",
    "\n",
    "is a well-known graph algorithm used to find the shortest path from a starting node to all other nodes in a weighted graph. The algorithm works by maintaining a set of nodes whose shortest distance from the source is known. It iteratively selects the node with the smallest tentative distance and updates its neighbors' distances. This process continues until the shortest paths to all nodes are found.\n",
    "\n",
    "  ##### Use Cases\n",
    "   - **Routing**: Dijkstra’s algorithm is commonly used in networking for routing protocols such as OSPF (Open Shortest Path First) and IS-IS (Intermediate System to Intermediate System).\n",
    "\n",
    "   - **GPS Navigation**: It is used in navigation systems to find the shortest path between locations.\n",
    "\n",
    "   - **Network Flow**: Used in problems involving shortest paths in communication networks or traffic systems.\n",
    "\n",
    "#### ``Breadth-First Search (BFS)`` \n",
    "\n",
    "is a graph traversal algorithm that explores all the nodes of a graph level by level, starting from a given source node. It uses a queue to store the nodes to be explored next, ensuring that the nearest unvisited node is processed first. BFS is particularly useful for unweighted graphs to find the shortest path from a source node to any other node.\n",
    "\n",
    "  ##### Use Cases\n",
    "   - **Finding the Shortest Path in Unweighted Graphs**: BFS is the go-to algorithm for finding the shortest path in a graph where all edges have the same weight.\n",
    "\n",
    "   - **Social Networks**: BFS is used to explore relationships between people, such as finding the shortest connection path between two users.\n",
    "\n",
    "   - **Web Crawling**: BFS can be used for web crawlers to explore all pages connected to a given page.\n",
    "\n",
    "\n",
    "#### Visualizing the Graph\n",
    "\n",
    "Both Dijkstra’s Algorithm and BFS can be visualized step-by-step to demonstrate the traversal or pathfinding process. These visualizations help in understanding how the algorithms work in real-time:\n",
    "\n",
    "- As ``Dijkstra’s Algorithm`` runs, the shortest path from the start node is gradually revealed, with edges marked in a specific color to show the path.\n",
    "\n",
    "- ``BFS`` traverses through the order of the nodes is visualized, showing the nodes being explored in layers.\n",
    "\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- Dijkstra’s Algorithm is ideal for finding the shortest paths in weighted graphs.\n",
    "\n",
    "- BFS is a simple and efficient graph traversal algorithm that works well for unweighted graphs and finding the shortest path in them.\n",
    "- Both algorithms can be visualized to provide a clear understanding of their step-by-step operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import heapq\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "# Define Dijkstra's algorithm\n",
    "def dijkstra(graph, start):\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    distances[start] = 0\n",
    "    priority_queue = [(0, start)]  # (distance, node)\n",
    "    \n",
    "    # For visualization: Store node updates\n",
    "    path_updates = {start: [start]}\n",
    "    \n",
    "    while priority_queue:\n",
    "        current_distance, current_node = heapq.heappop(priority_queue)\n",
    "\n",
    "        if current_distance > distances[current_node]:\n",
    "            continue\n",
    "\n",
    "        for neighbor, weight in graph[current_node].items():\n",
    "            distance = current_distance + weight\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                heapq.heappush(priority_queue, (distance, neighbor))\n",
    "\n",
    "                # Track the path to each node for visualization\n",
    "                path_updates[neighbor] = path_updates.get(current_node, []) + [neighbor]\n",
    "    \n",
    "    return distances, path_updates\n",
    "\n",
    "# Define the graph as an adjacency list with weights\n",
    "graph = {\n",
    "    'A': {'B': 7, 'C': 9},\n",
    "    'B': {'A': 7, 'C': 10, 'D': 15},\n",
    "    'C': {'A': 9, 'B': 10, 'D': 11},\n",
    "    'D': {'B': 15, 'C': 11, 'E': 6},\n",
    "    'E': {'D': 6, 'F': 9},\n",
    "    'F': {'E': 9}\n",
    "}\n",
    "\n",
    "# Run Dijkstra's algorithm\n",
    "start_node = 'A'\n",
    "distances, path_updates = dijkstra(graph, start_node)\n",
    "\n",
    "# Create a NetworkX graph for visualization\n",
    "G = nx.Graph()\n",
    "for node, neighbors in graph.items():\n",
    "    for neighbor, weight in neighbors.items():\n",
    "        G.add_edge(node, neighbor, weight=weight)\n",
    "\n",
    "# Visualization: Draw the initial graph\n",
    "pos = nx.spring_layout(G, seed=42)  # positions for all nodes\n",
    "\n",
    "# Jupyter-specific: Set inline mode\n",
    "%matplotlib inline\n",
    "\n",
    "# Draw the graph step-by-step\n",
    "def update_graph(step, delay=1):\n",
    "    clear_output(wait=True)  # Clear previous output for smoother animations\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    nx.draw(G, pos, with_labels=True, node_size=2000, node_color='skyblue', font_size=12, font_weight='bold', edge_color='gray')\n",
    "\n",
    "    # Highlight the nodes and edges for the current step\n",
    "    for node in path_updates:\n",
    "        if len(path_updates[node]) <= step:\n",
    "            nx.draw_networkx_nodes(G, pos, nodelist=[node], node_color='orange', node_size=3000)\n",
    "    \n",
    "    # Highlight the edges along the path\n",
    "    for node in path_updates:\n",
    "        for i in range(1, len(path_updates[node])):\n",
    "            nx.draw_networkx_edges(G, pos, edgelist=[(path_updates[node][i-1], path_updates[node][i])], edge_color='orange', width=2)\n",
    "\n",
    "    plt.title(f\"Dijkstra's Algorithm - Step {step + 1}\")\n",
    "    plt.show()\n",
    "    time.sleep(delay)  # Add delay for better visualization\n",
    "\n",
    "# Visualize each step with a delay\n",
    "for step in range(len(path_updates)):\n",
    "    update_graph(step, delay=1)  # Adjust delay time as needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "\n",
    "def bfs(graph, start):\n",
    "    visited = set()\n",
    "    queue = deque([start])\n",
    "    traversal_order = []\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            traversal_order.append(node)\n",
    "            for neighbor in graph[node]:\n",
    "                if neighbor not in visited:\n",
    "                    queue.append(neighbor)\n",
    "\n",
    "    return traversal_order\n",
    "\n",
    "\n",
    "graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['A', 'D', 'E'],\n",
    "    'C': ['A', 'F'],\n",
    "    'D': ['B'],\n",
    "    'E': ['B', 'F'],\n",
    "    'F': ['C', 'E']\n",
    "}\n",
    "\n",
    "\n",
    "print(bfs(graph, 'A'))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
