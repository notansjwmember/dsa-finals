{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Recursion\n",
    "\n",
    "#### Algorithm used (technique)\n",
    "\n",
    "``Recursion Backtracking``\n",
    "\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "Recursion backtracking is an algorithmic technique used to find all solutions to a problem by exploring all potential solutions incrementally. It involves calling the same function repeatedly with new parameters, diving deeper into the problem. Once a solution path fails (for example, when a queen cannot be placed in any column for a row in the n-Queens problem), the algorithm \"backtracks\" to the previous step and tries other possible options.\n",
    "\n",
    "\n",
    "- **Recursion** allows the algorithm to move step-by-step through a problem, progressing deeper into potential solutions.\n",
    "\n",
    "- **Backtracking** ensures that if a solution is not valid at any point, the algorithm will retract its steps and explore different possibilities from the previous level of recursion.\n",
    "\n",
    "- **Base Case** - When all conditions for a solution are met (e.g., all queens are placed on the board without conflicts), the algorithm adds the solution to the list.\n",
    "\n",
    "- **Termination Case** - If no valid solution is found after trying all possibilities, the algorithm ends that recursive path.\n",
    "\n",
    "\n",
    "##### Real World Problem\n",
    "\n",
    "``N-Queens Problem``\n",
    "\n",
    "A classic backtracking example where the goal is to place ``n`` queens on a ``n x n`` chessboard such that no two queens threaten each other.\n",
    "For each queen, the algorithm tries placing it in every column of a row, checking if the move is safe (i.e., the queen doesn't share the same column, diagonal, or anti-diagonal with other queens). If a queen can't be safely placed, the algorithm backtracks, moving the previous queens to different positions.\n",
    "\n",
    "\n",
    "#### Solution\n",
    "\n",
    "The backtracking recursion will go through the process of trying different configurations for the queens and will use backtracking when a conflict arises (when a queen can't be placed safely). Which continues until either a valid configuration is found or all possibilities are exhausted.\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "| **Recursion**            |                          | **Iterative**              |                          |\n",
    "| ------------------------ | ------------------------ | -------------------------- | ------------------------ |\n",
    "| **Advantages**            | - Simple and easy to implement.                             | **Advantages**             | - Avoids recursion stack overflow.                          |\n",
    "|                          | - Directly models the problem, making it intuitive.        |                           | - Can be more efficient for large problem sizes.             |\n",
    "|                          | - Good for small to medium-sized problems.                  |                           | - More control over the stack.                                |\n",
    "| **Limitations**           | - Can result in stack overflow for large problem sizes.    | **Limitations**            | - More complex to implement and reason about.                |\n",
    "|                          | - Can be less memory efficient due to recursion overhead.  |                           | - Requires manual management of state (stack).               |\n",
    "|                          | - Less efficient for very large inputs.                     |                           | - Less intuitive compared to recursion.                       |\n",
    "| **Use Case**              | - Best for smaller problems or where recursion depth is manageable. | **Use Case**              | - Best for larger problems where stack overflow is a concern. |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 solutions for 6-Queens:\n",
      ". Q . . . .\n",
      ". . . Q . .\n",
      ". . . . . Q\n",
      "Q . . . . .\n",
      ". . Q . . .\n",
      ". . . . Q .\n",
      "\n",
      ". . Q . . .\n",
      ". . . . . Q\n",
      ". Q . . . .\n",
      ". . . . Q .\n",
      "Q . . . . .\n",
      ". . . Q . .\n",
      "\n",
      ". . . Q . .\n",
      "Q . . . . .\n",
      ". . . . Q .\n",
      ". Q . . . .\n",
      ". . . . . Q\n",
      ". . Q . . .\n",
      "\n",
      ". . . . Q .\n",
      ". . Q . . .\n",
      "Q . . . . .\n",
      ". . . . . Q\n",
      ". . . Q . .\n",
      ". Q . . . .\n",
      "\n",
      "Backtracking completed in 0.000505 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def is_safe(board, row, col, n):\n",
    "    # Check if there's a queen in the same column\n",
    "    for i in range(row):\n",
    "        if board[i] == col or \\\n",
    "            board[i] - i == col - row or \\\n",
    "            board[i] + i == col + row:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def solve_n_queens(board, row, n, solutions):\n",
    "    # If all queens are placed successfully, add the solution\n",
    "    if row == n:\n",
    "        solutions.append(board[:])\n",
    "        return\n",
    "    \n",
    "    # Try placing queens in all columns for the current row\n",
    "    for col in range(n):\n",
    "        if is_safe(board, row, col, n):\n",
    "            board[row] = col  # Place the queen\n",
    "            solve_n_queens(board, row + 1, n, solutions)  # Recur for the next row\n",
    "            board[row] = -1  # Backtrack, remove the queen\n",
    "\n",
    "def print_solution(board):\n",
    "    for row in board:\n",
    "        line = ['Q' if col == row else '.' for col in range(len(board))]\n",
    "        print(\" \".join(line))\n",
    "    print()\n",
    "\n",
    "def n_queens(n):\n",
    "    solutions = []\n",
    "    board = [-1] * n  # Initialize the board with -1 (no queens placed)\n",
    "    \n",
    "    solve_n_queens(board, 0, n, solutions)\n",
    "    \n",
    "    print(f\"Found {len(solutions)} solutions for {n}-Queens:\")\n",
    "    for solution in solutions:\n",
    "        print_solution(solution)\n",
    "\n",
    "n = 6\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "n_queens(n)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Backtracking completed in {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def is_safe(board, row, col, n):\n",
    "    # Check if there's a queen in the same column or diagonal\n",
    "    for i in range(row):\n",
    "        if board[i] == col or \\\n",
    "            board[i] - i == col - row or \\\n",
    "            board[i] + i == col + row:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def solve_n_queens(n):\n",
    "    # Stack to store (row, board_state) tuples\n",
    "    stack = []\n",
    "    solutions = []\n",
    "\n",
    "    # Initialize the board with -1 (no queens placed)\n",
    "    board = [-1] * n\n",
    "    row = 0  # Start at the first row\n",
    "\n",
    "    while row >= 0:\n",
    "        # Try placing a queen in the current row\n",
    "        found_safe_col = False\n",
    "        for col in range(board[row] + 1, n):\n",
    "            if is_safe(board, row, col, n):\n",
    "                board[row] = col  # Place queen in column\n",
    "                stack.append((row, board[:]))  # Save the current state\n",
    "                found_safe_col = True\n",
    "                break  # Move to the next row\n",
    "        \n",
    "        if not found_safe_col:\n",
    "            if row == 0:  # No solution found, we're done\n",
    "                break\n",
    "            board[row] = -1  # Backtrack: remove the queen\n",
    "            row -= 1  # Go back to the previous row\n",
    "        else:\n",
    "            row += 1  # Move to the next row\n",
    "    \n",
    "        # Check if we've reached the last row\n",
    "        if row == n:\n",
    "            solutions.append(board[:])  # Found a solution\n",
    "            row -= 1  # Backtrack\n",
    "\n",
    "    # Output all solutions\n",
    "    print(f\"Found {len(solutions)} solutions for {n}-Queens:\")\n",
    "    for solution in solutions:\n",
    "        for row in solution:\n",
    "            line = ['Q' if col == row else '.' for col in range(n)]\n",
    "            print(\" \".join(line))\n",
    "        print()\n",
    "\n",
    "    return solutions\n",
    "\n",
    "n = 6\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "solve_n_queens(n)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "print(f\"Iterative backtracking completed in {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sorting\n",
    "\n",
    "#### Algorithms used \n",
    "\n",
    "`Quick sort` & `Selection sort`\n",
    "\n",
    "#### Explanation\n",
    "\n",
    " ``Selection Sort`` works by repeatedly selecting the minimum element from an unsorted portion of the list and swapping it with the element at the beginning of that portion. It continues this process until the entire list is sorted.\n",
    "\n",
    " ``Quick Sort`` is a divide-and-conquer technique. It works by selecting a pivot element from the list and partitioning the other elements into two sublists—those less than the pivot and those greater than the pivot. The algorithm then recursively sorts the sublists.\n",
    "\n",
    "\n",
    "#### Real World Problems\n",
    "\n",
    "This type of sorting might be used in applications like:\n",
    "\n",
    "- ``File Management Systems`` for large collections of files by name, creation date, or file size.\n",
    "\n",
    "- ``Financial Data`` for random financial numbers for analysis, such as transaction amounts.\n",
    "\n",
    "- ``Event Scheduling`` for dates for planning events, appointments, or deadlines.\n",
    "\n",
    "\n",
    "#### Time Complexity Comparison \n",
    "*May vary since this data was taken from a previous run*\n",
    "\n",
    "| **Selection Sort**                | **Time Elapsed (Small Data)** | **Time Elapsed (Large Data)** | **Quick Sort**                | **Time Elapsed (Small Data)** | **Time Elapsed (Large Data)** |\n",
    "| --------------------------------- | ----------------------------- | ----------------------------- | ----------------------------- | ----------------------------- | ----------------------------- |\n",
    "| **Files**                         | 0.000279 seconds              | 0.019954 seconds              | **Files**                     | 0.000049 seconds              | 0.000955 seconds              |\n",
    "| **Numbers**                       | 0.000036 seconds              | 0.014498 seconds              | **Numbers**                   | 0.000037 seconds              | 0.001041 seconds              |\n",
    "| **Dates**                         | 0.000033 seconds              | 0.019670 seconds              | **Dates**                     | 0.000037 seconds              | 0.001305 seconds              |\n",
    "\n",
    "\n",
    "\n",
    "#### Key Takeaways\n",
    "\n",
    "- ``Quick Sort`` outperforms ``Selection Sort`` as the data size grows, both for small and large datasets.\n",
    "\n",
    "- For small data, both algorithms show negligible time differences, but ``Quick Sort`` is faster.\n",
    "\n",
    "- As the data size increases, ``Quick Sort`` remains significantly faster, especially when dealing with large datasets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def generate_filenames(n):\n",
    "    return [f\"file_{i}.txt\" for i in range(1, n+1)]\n",
    "\n",
    "def generate_random_numbers(n, start=1, end=1000):\n",
    "    return [random.randint(start, end) for _ in range(n)]\n",
    "\n",
    "def generate_random_dates(n):\n",
    "    start_date = datetime(2020, 1, 1)\n",
    "    return [start_date + timedelta(days=random.randint(0, 1000)) for _ in range(n)]\n",
    "\n",
    "def selection_sort(arr):\n",
    "    n = len(arr)\n",
    "    for i in range(n):\n",
    "        min_idx = i\n",
    "        for j in range(i+1, n):\n",
    "            if arr[j] < arr[min_idx]:\n",
    "                min_idx = j\n",
    "        arr[i], arr[min_idx] = arr[min_idx], arr[i]\n",
    "    return arr\n",
    "\n",
    "def quick_sort(arr):\n",
    "    if len(arr) <= 1:\n",
    "        return arr\n",
    "    pivot = arr[len(arr) // 2]\n",
    "    left = [x for x in arr if x < pivot]\n",
    "    middle = [x for x in arr if x == pivot]\n",
    "    right = [x for x in arr if x > pivot]\n",
    "    return quick_sort(left) + middle + quick_sort(right)\n",
    "\n",
    "small_dataset_size = 10\n",
    "large_dataset_size = 1000\n",
    "\n",
    "small_files = generate_filenames(small_dataset_size)\n",
    "large_files = generate_filenames(large_dataset_size)\n",
    "\n",
    "small_numbers = generate_random_numbers(small_dataset_size)\n",
    "large_numbers = generate_random_numbers(large_dataset_size)\n",
    "\n",
    "small_dates = generate_random_dates(small_dataset_size)\n",
    "large_dates = generate_random_dates(large_dataset_size)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Data to process\n",
    "print(\"Processing mock files..\\n\")\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Small data:\")\n",
    "\n",
    "# For selection sort\n",
    "sorted_small_files_selection = selection_sort(small_files.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Selection Sort - Small Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.time()\n",
    "sorted_small_files_quick = quick_sort(small_files.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Quick Sort - Small Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Large data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.time()\n",
    "sorted_large_files_selection = selection_sort(large_files.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Selection Sort - Large Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.time()\n",
    "sorted_large_files_quick = quick_sort(large_files.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Quick Sort - Large Files: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Data to process\n",
    "print(\"Processing mock numbers..\\n\")\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Small data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.time()\n",
    "sorted_small_numbers_selection = selection_sort(small_numbers.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Selection Sort - Small Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.time()\n",
    "sorted_small_numbers_quick = quick_sort(small_numbers.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Quick Sort - Small Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Large data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.time()\n",
    "sorted_large_numbers_selection = selection_sort(large_numbers.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Selection Sort - Large Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.time()\n",
    "sorted_large_numbers_quick = quick_sort(large_numbers.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Quick Sort - Large Numbers: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Data to process\n",
    "print(\"Processing mock dates..\\n\")\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Small data:\")\n",
    "\n",
    "# For selection sort\n",
    "start_time = time.time()\n",
    "sorted_small_dates_selection = selection_sort(small_dates.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Selection Sort - Small Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.time()\n",
    "sorted_small_dates_quick = quick_sort(small_dates.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Quick Sort - Small Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "print()\n",
    "\n",
    "# Size of data to process\n",
    "print(\"Large data:\")\n",
    "\n",
    "# For selection\n",
    "start_time = time.time()\n",
    "sorted_large_dates_selection = selection_sort(large_dates.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Selection Sort - Large Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n",
    "\n",
    "# For quick sort\n",
    "start_time = time.time()\n",
    "sorted_large_dates_quick = quick_sort(large_dates.copy())\n",
    "end_time = time.time()\n",
    "print(f\"Quick Sort - Large Dates: Time elapsed: {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search\n",
    "\n",
    "#### Algorithms Used\n",
    "\n",
    "`Binary Search` & `Interpolation Search`\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "Both Binary Search and Interpolation Search are efficient searching algorithms used to find a specific element in a sorted dataset. The two differ in how they navigate through the data:\n",
    "\n",
    "``Binary Search``\n",
    "\n",
    "- **Divide and conquer** strategy.\n",
    "\n",
    "- Works by repeatedly dividing the search space in half.\n",
    "\n",
    "- The algorithm compares the target with the middle element and narrows down the search space to either the left or right half.\n",
    "\n",
    "- **Time Complexity**: O(log n).\n",
    "\n",
    "``Interpolation Search``\n",
    "\n",
    "- **Estimate the position** of the target based on the value.\n",
    "\n",
    "- It assumes that the values are uniformly distributed, estimating the target’s position based on a linear interpolation between the low and high bounds.\n",
    "\n",
    "- If the estimate points to an element that isn’t the target, the search space is adjusted accordingly.\n",
    "\n",
    "- **Time Complexity**: O(log log n) in best-case, but can degrade to O(n) in the worst case.\n",
    "\n",
    "Both algorithms are designed for sorted datasets but have different use cases based on the distribution of the data.\n",
    "\n",
    "##### Real World Problem\n",
    "\n",
    " - **Binary Search** (Stock Price Lookup)\n",
    "    - Imagine you are trying to find the stock price on a specific date from a list of sorted dates and prices. Binary Search is ideal here because the data is already sorted (by date), and you can efficiently find the price for any given date by halving the search space with each comparison.\n",
    "\n",
    " - **Interpolation Search** (Predicting the Value)\n",
    "    - For predicting values (such as sales for a given year), Interpolation Search is useful when the data is uniformly distributed. The algorithm estimates the target’s position based on the values surrounding it, offering a more efficient search for large datasets where the values are evenly spaced.\n",
    "\n",
    "#### Solution\n",
    "\n",
    "- **Binary Search** narrows down the search to the date of interest. This allows for efficient retrieval of the stock price on that date.\n",
    "\n",
    "- **Interpolation Search** estimates the position of the target year based on the years provided. If the data points (e.g., sales over multiple years) are evenly distributed, this search method will be faster than Binary Search in terms of comparisons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Sample data: List of dates and corresponding stock prices\n",
    "dates = ['2023-01-01', '2023-02-01', '2023-03-01', '2023-04-01', '2023-05-01']\n",
    "prices = [150, 170, 160, 180, 175]\n",
    "\n",
    "# Binary Search Implementation\n",
    "def binary_search(dates, target_date):\n",
    "    low, high = 0, len(dates) - 1\n",
    "    while low <= high:\n",
    "        mid = (low + high) // 2\n",
    "        if dates[mid] == target_date:\n",
    "            return mid  # Return the index where the date is found\n",
    "        elif dates[mid] < target_date:\n",
    "            low = mid + 1\n",
    "        else:\n",
    "            high = mid - 1\n",
    "    return -1  # Return -1 if the date is not found\n",
    "\n",
    "# Example of using binary search to find the price on a specific date\n",
    "target_date = '2023-03-01'\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "index = binary_search(dates, target_date)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "if index != -1:\n",
    "    print(f\"The stock price on {target_date} was {prices[index]}\")\n",
    "else:\n",
    "    print(f\"Stock price for {target_date} not found\")\n",
    "    \n",
    "print(f\"Search completed in {end_time - start_time:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Sample data: List of years and corresponding sales data\n",
    "years = [2000, 2005, 2010, 2012, 2015, 2020]\n",
    "sales = [100, 150, 200, 250, 300, 400]\n",
    "\n",
    "# Interpolation Search Implementation\n",
    "def interpolation_search(years, target_year):\n",
    "    low, high = 0, len(years) - 1\n",
    "    while low <= high and target_year >= years[low] and target_year <= years[high]:\n",
    "        # Calculate the position of the target year using interpolation formula\n",
    "        pos = low + ((target_year - years[low]) * (high - low)) // (years[high] - years[low])\n",
    "        \n",
    "        # Check if the target year is found at pos\n",
    "        if years[pos] == target_year:\n",
    "            return pos  # Return the index if the year is found\n",
    "        elif years[pos] < target_year:\n",
    "            low = pos + 1\n",
    "        else:\n",
    "            high = pos - 1\n",
    "    return -1  # Return -1 if the year is not found\n",
    "\n",
    "# Example of using interpolation search to predict sales for a specific year\n",
    "target_year = 2012\n",
    "\n",
    "start_time = time.perf_counter()\n",
    "index = interpolation_search(years, target_year)\n",
    "end_time = time.perf_counter()\n",
    "\n",
    "if index != -1:\n",
    "    print(f\"Sales in {target_year} were predicted to be {sales[index]}\")\n",
    "else:\n",
    "    print(f\"Sales data for {target_year} not found\")\n",
    "    \n",
    "print(f\"Search completed in {end_time - start_time:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "``Dynamic Programming (DP)`` is an optimization technique used to solve problems by breaking them down into smaller subproblems and storing the results of these subproblems to avoid redundant calculations. It is particularly useful when a problem can be divided into overlapping subproblems.\n",
    "\n",
    "- **Memoization**: DP uses a bottom-up approach where we store results of subproblems in a table (or array) to avoid recalculating them repeatedly.\n",
    "\n",
    "- **Optimal Substructure**: The solution to a problem depends on solutions to smaller subproblems, which is the key property of DP.\n",
    "\n",
    "- **Overlapping Subproblems**: The problem can be broken down into subproblems which are solved multiple times, and these subproblems can be solved independently.\n",
    "\n",
    "##### Real World Problems\n",
    "\n",
    " ``Fibonacci Problem`` involves calculating the nth Fibonacci number where each number is the sum of the two preceding ones. DP helps to store previous Fibonacci numbers to avoid recalculating them repeatedly.\n",
    "\n",
    " ``Knapsack Problem`` is a classical optimization problem where you have a set of items, each with a weight and a value, and a knapsack with a weight limit. The goal is to maximize the total value of the items without exceeding the capacity of the knapsack.\n",
    "\n",
    "#### Comparison\n",
    "\n",
    "| **Dynamic Programming**           |                              | **Recursion**               |                              |\n",
    "|-----------------------------------|------------------------------|-----------------------------|------------------------------|\n",
    "| **Advantages**                    | - More efficient for large inputs due to memoization. | **Advantages**              | - Simple and easy to implement.                             |\n",
    "|                                   | - Avoids redundant calculations, saving time. |                             | - Directly models the problem, making it intuitive.        |\n",
    "|                                   | - Suitable for problems with overlapping subproblems. |                             | - Good for small to medium-sized problems.                  |\n",
    "| **Limitations**                   | - May use a lot of memory to store intermediate results. | **Limitations**             | - Can result in stack overflow for large problem sizes.    |\n",
    "|                                   | - Requires more time to set up compared to recursive solutions. |                             | - Can be less memory efficient due to recursion overhead.  |\n",
    "|                                   | - Requires more complex logic for table management. |                             | - Less efficient for very large inputs.                     |\n",
    "| **Use Case**                      | - Best for problems with overlapping subproblems or when optimization is required. | **Use Case**               | - Best for smaller problems or when recursion depth is manageable. |\n",
    "| **Time Complexity**               | O(n) for Fibonacci, O(n*W) for Knapsack, where `W` is the knapsack capacity. | **Time Complexity**         | O(2^n) for Fibonacci, which grows exponentially. |\n",
    "| **Space Complexity**              | O(n) for Fibonacci, O(n*W) for Knapsack. | **Space Complexity**        | O(n) for Fibonacci (due to recursion stack).  |\n",
    "| **Execution Time (for n=10)**     | 0.000015 seconds             | **Execution Time**          | 0.000925 seconds             |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Fibonacci using Dynamic Programming (DP)\n",
    "def fibonacci_dp(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "\n",
    "    dp = [0] * (n + 1)\n",
    "    dp[0], dp[1] = 0, 1\n",
    "    \n",
    "    for i in range(2, n + 1):\n",
    "        dp[i] = dp[i - 1] + dp[i - 2]\n",
    "    \n",
    "    return dp[n]\n",
    "\n",
    "# Measure performance for Fibonacci DP\n",
    "start_time = time.perf_counter()\n",
    "print(\"Fibonacci DP Result:\", fibonacci_dp(10))  # Calculate Fibonacci for n=10\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Fibonacci DP Execution Time: {end_time - start_time:0.6f} seconds\")\n",
    "\n",
    "# Knapsack Problem using Dynamic Programming (DP)\n",
    "def knapsack_dp(weights, values, capacity):\n",
    "    n = len(weights)\n",
    "    dp = [[0] * (capacity + 1) for _ in range(n + 1)]\n",
    "    \n",
    "    for i in range(1, n + 1):\n",
    "        for w in range(capacity + 1):\n",
    "            if weights[i - 1] <= w:\n",
    "                dp[i][w] = max(dp[i - 1][w], dp[i - 1][w - weights[i - 1]] + values[i - 1])\n",
    "            else:\n",
    "                dp[i][w] = dp[i - 1][w]\n",
    "\n",
    "    return dp[n][capacity]\n",
    "\n",
    "# Measure performance for Knapsack DP\n",
    "start_time = time.perf_counter()\n",
    "weights = [1, 3, 4, 5]\n",
    "values = [10, 40, 50, 70]\n",
    "capacity = 8\n",
    "print(\"\\nKnapsack DP Result:\", knapsack_dp(weights, values, capacity))  # Solve Knapsack problem\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Knapsack DP Execution Time: {end_time - start_time:0.6f} seconds\")\n",
    "\n",
    "# Fibonacci using Recursive Approach\n",
    "def fibonacci_recursive(n):\n",
    "    if n == 0:\n",
    "        return 0\n",
    "    if n == 1:\n",
    "        return 1\n",
    "    return fibonacci_recursive(n - 1) + fibonacci_recursive(n - 2)\n",
    "\n",
    "# Measure performance for Fibonacci Recursive\n",
    "start_time = time.perf_counter()\n",
    "print(\"\\nFibonacci Recursive Result:\", fibonacci_recursive(10))  # Calculate Fibonacci for n=10\n",
    "end_time = time.perf_counter()\n",
    "print(f\"Fibonacci Recursive Execution Time: {end_time - start_time:0.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Greedy\n",
    "\n",
    "### Explanation\n",
    "\n",
    "The ``Greedy Algorithm`` for the Knapsack problem works by making the best choice at each step based on a specific criterion, which is typically the **value-to-weight ratio** of the items. The items are first sorted by their value-to-weight ratio in descending order, and then they are added to the knapsack until the capacity is reached. If an item cannot be completely added (due to capacity limitations), it is included fractionally.\n",
    "\n",
    "\n",
    "``Strengths``\n",
    "\n",
    "- **Efficiency**: Greedy algorithms are generally fast, with a time complexity of \\(O(n \\log n)\\) due to the sorting step.\n",
    "\n",
    "- **Simplicity**: The greedy approach is easy to understand and implement, requiring fewer computational steps compared to other methods.\n",
    "\n",
    "- **Low Space Complexity**: Greedy algorithms typically require \\(O(n)\\) space, as they only need to store the items and their corresponding ratios.\n",
    "\n",
    "``Limitations``\n",
    "\n",
    "- **Suboptimal Solution**: Greedy algorithms may not always provide the optimal solution. Since the algorithm makes decisions based on local optimization (best immediate choice), it may fail to find the best global solution.\n",
    "\n",
    "- **Limited Applicability**: This approach works well only for problems with the **greedy-choice property** and **optimal substructure**, which may not be present in all optimization problems.\n",
    "\n",
    "- **No Backtracking**: Once a decision is made, the algorithm doesn't reconsider it. This can result in missing out on better choices that may have emerged later.\n",
    "\n",
    "\n",
    "#### Divide-and-Conquer Approach\n",
    "\n",
    "The ``Divide-and-Conquer`` approach for the Knapsack problem involves breaking the problem down into smaller subproblems. Specifically, the problem is divided by recursively deciding whether to include an item or exclude it, while tracking the best total value for each combination of included/excluded items. The decision process follows these steps:\n",
    "\n",
    "1. If the current item can fit in the knapsack (i.e., its weight is less than or equal to the remaining capacity), both the inclusion and exclusion of the item are considered.\n",
    "\n",
    "2. The process is repeated for smaller subproblems, until all items are either considered or excluded.\n",
    "\n",
    "This method guarantees an optimal solution, but it has an exponential time complexity of \\(O(2^n)\\), making it inefficient for large problem sizes. It is primarily used when the problem is small enough or when a recursive approach is desired.\n",
    "\n",
    "\n",
    "#### Comparison of Solutions\n",
    "\n",
    "| Algorithm               | Time Complexity   | Space Complexity | Optimal Solution? | When to Use                                       |\n",
    "|-------------------------|-------------------|------------------|------------------|--------------------------------------------------|\n",
    "| **Greedy Knapsack**      | \\(O(n \\log n)\\)   | \\(O(n)\\)         | No               | Suitable when an approximate solution is acceptable, or when greedy-choice property holds. |\n",
    "| **Dynamic Programming**  | \\(O(n \\times W)\\) | \\(O(n \\times W)\\) | Yes              | Best when an exact solution is needed, and the problem size is manageable. |\n",
    "| **Divide and Conquer**   | \\(O(2^n)\\)        | \\(O(n)\\)         | Yes              | Useful for small problems or when a recursive approach is preferred. |\n",
    "\n",
    "\n",
    "#### Performance Comparison\n",
    "\n",
    "| Algorithm               | Time Complexity   | Space Complexity | Optimal Solution | When to Use                                       |\n",
    "|-------------------------|-------------------|------------------|------------------|--------------------------------------------------|\n",
    "| **Greedy**              | \\(O(n \\log n)\\)   | \\(O(n)\\)         | No               | When an approximate solution is acceptable. |\n",
    "| **Dynamic Programming** | \\(O(n \\times W)\\) | \\(O(n \\times W)\\) | Yes              | When an exact solution is needed for a given capacity. |\n",
    "| **Divide-and-Conquer**  | \\(O(2^n)\\)        | \\(O(n)\\)         | Yes              | Suitable for small problems or when a recursive approach is desired. |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.0\n",
      "110\n"
     ]
    }
   ],
   "source": [
    "def greedy_knapsack(weights, values, capacity):\n",
    "    n = len(weights)\n",
    "    items = sorted([(values[i], weights[i], values[i] / weights[i]) for i in range(n)], \n",
    "    key=lambda x: x[2], reverse=True)\n",
    "\n",
    "    total_value = 0\n",
    "    for value, weight, ratio in items:\n",
    "        if capacity >= weight:\n",
    "            capacity -= weight\n",
    "            total_value += value\n",
    "        else:  \n",
    "            total_value += value * (capacity / weight)\n",
    "            break\n",
    "\n",
    "    return total_value\n",
    "\n",
    "weights = [1, 3, 4, 5]\n",
    "values = [10, 40, 50, 70]\n",
    "capacity = 8\n",
    "print(greedy_knapsack(weights, values, capacity))  \n",
    "\n",
    "def knapsack_divide_and_conquer(weights, values, capacity, n):\n",
    "    if n == 0 or capacity == 0:\n",
    "        return 0\n",
    "\n",
    "    if weights[n - 1] > capacity:\n",
    "        return knapsack_divide_and_conquer(weights, values, capacity, n - 1)\n",
    "\n",
    "    \n",
    "    include = values[n - 1] + knapsack_divide_and_conquer(weights, values, capacity - weights[n - 1], n - 1)\n",
    "    exclude = knapsack_divide_and_conquer(weights, values, capacity, n - 1)\n",
    "\n",
    "    return max(include, exclude)\n",
    "\n",
    "weights = [1, 3, 4, 5]\n",
    "values = [10, 40, 50, 70]\n",
    "capacity = 8\n",
    "n = len(weights)\n",
    "print(knapsack_divide_and_conquer(weights, values, capacity, n))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Algorithms\n",
    "\n",
    "#### Explanation\n",
    "\n",
    "#### ``Dijkstra’s Algorithm``\n",
    "\n",
    "is a well-known graph algorithm used to find the shortest path from a starting node to all other nodes in a weighted graph. The algorithm works by maintaining a set of nodes whose shortest distance from the source is known. It iteratively selects the node with the smallest tentative distance and updates its neighbors' distances. This process continues until the shortest paths to all nodes are found.\n",
    "\n",
    "  ##### Use Cases\n",
    "   - **Routing**: Dijkstra’s algorithm is commonly used in networking for routing protocols such as OSPF (Open Shortest Path First) and IS-IS (Intermediate System to Intermediate System).\n",
    "\n",
    "   - **GPS Navigation**: It is used in navigation systems to find the shortest path between locations.\n",
    "\n",
    "   - **Network Flow**: Used in problems involving shortest paths in communication networks or traffic systems.\n",
    "\n",
    "#### ``Breadth-First Search (BFS)`` \n",
    "\n",
    "is a graph traversal algorithm that explores all the nodes of a graph level by level, starting from a given source node. It uses a queue to store the nodes to be explored next, ensuring that the nearest unvisited node is processed first. BFS is particularly useful for unweighted graphs to find the shortest path from a source node to any other node.\n",
    "\n",
    "  ##### Use Cases\n",
    "   - **Finding the Shortest Path in Unweighted Graphs**: BFS is the go-to algorithm for finding the shortest path in a graph where all edges have the same weight.\n",
    "\n",
    "   - **Social Networks**: BFS is used to explore relationships between people, such as finding the shortest connection path between two users.\n",
    "\n",
    "   - **Web Crawling**: BFS can be used for web crawlers to explore all pages connected to a given page.\n",
    "\n",
    "\n",
    "#### Visualizing the Graph\n",
    "\n",
    "Both Dijkstra’s Algorithm and BFS can be visualized step-by-step to demonstrate the traversal or pathfinding process. These visualizations help in understanding how the algorithms work in real-time:\n",
    "\n",
    "- As ``Dijkstra’s Algorithm`` runs, the shortest path from the start node is gradually revealed, with edges marked in a specific color to show the path.\n",
    "\n",
    "- ``BFS`` traverses through the order of the nodes is visualized, showing the nodes being explored in layers.\n",
    "\n",
    "\n",
    "#### Summary\n",
    "\n",
    "- Dijkstra’s Algorithm is ideal for finding the shortest paths in weighted graphs.\n",
    "\n",
    "- BFS is a simple and efficient graph traversal algorithm that works well for unweighted graphs and finding the shortest path in them.\n",
    "- Both algorithms can be visualized to provide a clear understanding of their step-by-step operation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mheapq\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcollections\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m deque\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "def visualize_graph(graph, traversal=None, shortest_paths=None, start=None):\n",
    "    G = nx.Graph()\n",
    "    for node, edges in graph.items():\n",
    "        for edge in edges:\n",
    "            G.add_edge(node, edge[0], weight=edge[1])\n",
    "\n",
    "    pos = nx.spring_layout(G)\n",
    "    nx.draw(G, pos, with_labels=True, node_color='lightblue', edge_color='gray', font_weight='bold')\n",
    "\n",
    "    if traversal:\n",
    "        path_edges = [(traversal[i], traversal[i + 1]) for i in range(len(traversal) - 1)]\n",
    "        nx.draw_networkx_edges(G, pos, edgelist=path_edges, edge_color='blue', width=2)\n",
    "\n",
    "    if shortest_paths and start:\n",
    "        for target, path in shortest_paths.items():\n",
    "            if start != target:\n",
    "                nx.draw_networkx_edges(G, pos, edgelist=path, edge_color='green', width=2)\n",
    "                \n",
    "    plt.show()\n",
    "\n",
    "def dijkstra(graph, start):\n",
    "    \n",
    "    pq = []\n",
    "    heapq.heappush(pq, (0, start))\n",
    "    distances = {node: float('inf') for node in graph}\n",
    "    distances[start] = 0\n",
    "    visited = set()\n",
    "\n",
    "    while pq:\n",
    "        current_distance, current_node = heapq.heappop(pq)\n",
    "        if current_node in visited:\n",
    "            continue\n",
    "        visited.add(current_node)\n",
    "\n",
    "        for neighbor, weight in graph[current_node]:\n",
    "            distance = current_distance + weight\n",
    "            if distance < distances[neighbor]:\n",
    "                distances[neighbor] = distance\n",
    "                heapq.heappush(pq, (distance, neighbor))\n",
    "\n",
    "    return distances\n",
    "\n",
    "graph = {\n",
    "    'A': [('B', 1), ('C', 4)],\n",
    "    'B': [('A', 1), ('C', 2), ('D', 5)],\n",
    "    'C': [('A', 4), ('B', 2), ('D', 1)],\n",
    "    'D': [('B', 5), ('C', 1)]\n",
    "}\n",
    "\n",
    "print(dijkstra(graph, 'A'))  \n",
    "\n",
    "\n",
    "def bfs(graph, start):\n",
    "    visited = set()\n",
    "    queue = deque([start])\n",
    "    traversal_order = []\n",
    "\n",
    "    while queue:\n",
    "        node = queue.popleft()\n",
    "        if node not in visited:\n",
    "            visited.add(node)\n",
    "            traversal_order.append(node)\n",
    "            for neighbor in graph[node]:\n",
    "                if neighbor not in visited:\n",
    "                    queue.append(neighbor)\n",
    "\n",
    "    return traversal_order\n",
    "\n",
    "\n",
    "graph = {\n",
    "    'A': ['B', 'C'],\n",
    "    'B': ['A', 'D', 'E'],\n",
    "    'C': ['A', 'F'],\n",
    "    'D': ['B'],\n",
    "    'E': ['B', 'F'],\n",
    "    'F': ['C', 'E']\n",
    "}\n",
    "\n",
    "\n",
    "print(bfs(graph, 'A'))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
